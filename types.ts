
/**
 * Defines the application operation modes.
 * - ADULT: Standard interface with tracked statistics and sophisticated visuals.
 * - KID: Simplified interface, gamified elements, larger touch targets, and child-friendly content.
 */
export enum AppMode {
  Adult = 'ADULT',
  Kid = 'KID'
}

/**
 * Supported image resolutions for generation.
 * These map to the capabilities of the `gemini-3-pro-image-preview` model.
 */
export enum ImageSize {
  Size_1K = '1K',
  Size_2K = '2K',
  Size_4K = '4K'
}

/**
 * Predefined voice personas for Text-to-Speech generation.
 * These correspond to the `prebuiltVoiceConfig` names available in the Gemini API.
 */
export enum VoiceName {
  Puck = 'Puck',
  Charon = 'Charon',
  Kore = 'Kore',
  Fenrir = 'Fenrir',
  Zephyr = 'Zephyr',
  Aoede = 'Aoede',
  Leda = 'Leda',
  Orpheus = 'Orpheus',
  Iapetus = 'Iapetus',
  Leto = 'Leto',
  Mnemosyne = 'Mnemosyne'
}

/**
 * Represents a completely generated meditation session including all assets.
 */
export interface MeditationSession {
  /** Unique identifier for the session (timestamp based) */
  id: string;
  /** Title of the meditation generated by the LLM */
  title: string;
  /** The full text transcript of the guided meditation */
  script: string;
  /** The selected mood or goal (e.g., "Sleep", "Focus") */
  mood: string;
  /** Approximate duration category ("Short" or "Long") */
  duration: string; 
  /** Description of the visual style selected by the user */
  visualStyle: string;
  /** The AI-generated prompt used to create the background image */
  visualPrompt: string;
  /** Base64 data URL of the generated background image */
  imageUrl?: string;
  /** Decoded AudioBuffer ready for playback via Web Audio API */
  audioBuffer?: AudioBuffer;
  /** Timestamp of creation in milliseconds */
  createdAt: number;
}

/**
 * Represents a single message in the chat history.
 */
export interface ChatMessage {
  /** Unique ID for the message */
  id: string;
  /** The speaker: 'user' for human input, 'model' for the AI assistant */
  role: 'user' | 'model';
  /** The content of the message */
  text: string;
  /** Timestamp of the message */
  timestamp: number;
}

/**
 * Interface representing the structure of the session creation form data.
 * Used to track user selections through the multi-step wizard.
 */
export interface SessionFormData {
  /** The intended goal or feeling for the session */
  mood: string;
  /** The visual theme for the generated background */
  visualStyle: string;
  /** The resolution of the generated image */
  imageSize: ImageSize;
  /** The specific TTS voice persona to use */
  voice: VoiceName;
  /** The requested length of the session */
  duration: string;
}

// --- Web Speech API Type Definitions ---
// These interfaces provide strict typing for the browser's native SpeechRecognition API,
// which is often missing from standard TypeScript lib definitions.

/**
 * Interface for the SpeechRecognition API entry point.
 */
export interface ISpeechRecognition extends EventTarget {
  /** If true, continues listening after the first result. We use false for single-command mode. */
  continuous: boolean;
  /** If true, returns provisional results (typing effect). We use true for better UX. */
  interimResults: boolean;
  /** Language tag (e.g., 'en-US') */
  lang: string;
  /** Starts the speech recognition service */
  start(): void;
  /** Stops the speech recognition service */
  stop(): void;
  /** Aborts the speech recognition service immediately */
  abort(): void;
  onstart: ((this: ISpeechRecognition, ev: Event) => void) | null;
  onend: ((this: ISpeechRecognition, ev: Event) => void) | null;
  onerror: ((this: ISpeechRecognition, ev: ISpeechRecognitionErrorEvent) => void) | null;
  onresult: ((this: ISpeechRecognition, ev: ISpeechRecognitionEvent) => void) | null;
}

/**
 * Event object for SpeechRecognition errors.
 */
export interface ISpeechRecognitionErrorEvent extends Event {
  /** The type of error that occurred */
  error: 'no-speech' | 'aborted' | 'audio-capture' | 'network' | 'not-allowed' | 'service-not-allowed' | 'bad-grammar' | 'language-not-supported' | string;
  /** Descriptive message */
  message: string;
}

/**
 * Event object for SpeechRecognition results.
 */
export interface ISpeechRecognitionEvent extends Event {
  /** The index of the current result */
  resultIndex: number;
  /** The list of all results */
  results: ISpeechRecognitionResultList;
}

/**
 * List of speech recognition results.
 */
export interface ISpeechRecognitionResultList {
  length: number;
  item(index: number): ISpeechRecognitionResult;
  [index: number]: ISpeechRecognitionResult;
}

/**
 * Single speech recognition result, containing alternatives.
 */
export interface ISpeechRecognitionResult {
  /** True if this result is final (not interim) */
  isFinal: boolean;
  length: number;
  item(index: number): ISpeechRecognitionAlternative;
  [index: number]: ISpeechRecognitionAlternative;
}

/**
 * Single recognition alternative with transcript and confidence score.
 */
export interface ISpeechRecognitionAlternative {
  /** The transcribed text */
  transcript: string;
  /** Confidence score between 0 and 1 */
  confidence: number;
}
